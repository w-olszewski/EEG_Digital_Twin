{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import csv \n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as stats\n",
    "\n",
    "file_path = 'path to file'\n",
    "csv_folder = 'path to file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_df['SubjectID'] = excel_df['setfile'].str.extract(r'/(aaaaa\\w+)')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in excel_df.iterrows():\n",
    "    subject_id = row['SubjectID']\n",
    "    initial_similarity_csv_filename = f\"{subject_id}_initial_similarity.csv\"\n",
    "    initial_similarity_csv_path = os.path.join(csv_folder, initial_similarity_csv_filename)\n",
    "    if os.path.exists(initial_similarity_csv_path):\n",
    "        initial_similarity_value = pd.read_csv(initial_similarity_csv_path, header=None).iloc[0, 0]\n",
    "        excel_df.at[index, 'Initial Similarity'] = initial_similarity_value\n",
    "\n",
    "# Save the modified Excel DataFrame back to the same file using openpyxl (default engine for .xlsx)\n",
    "excel_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in excel_df.iterrows():\n",
    "    subject_id = row['SubjectID']\n",
    "    similarity_csv_filename = f\"{subject_id}_similarity.csv\"\n",
    "    similarity_csv_path = os.path.join(csv_folder, similarity_csv_filename)\n",
    "    if os.path.exists(similarity_csv_path):\n",
    "        similarity_value = pd.read_csv(similarity_csv_path, header=None).iloc[0, 0]\n",
    "        excel_df.at[index, 'Similarity'] = similarity_value\n",
    "\n",
    "# Save the modified Excel DataFrame back to the same file using openpyxl (default engine for .xlsx)\n",
    "excel_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in excel_df.iterrows():\n",
    "    subject_id = row['SubjectID']\n",
    "    csv_filename = f\"{subject_id}_parameters.csv\"  # Construct CSV filename\n",
    "    csv_path = os.path.join(csv_folder, csv_filename)\n",
    "    if os.path.exists(csv_path):\n",
    "        csv_data = pd.read_csv(csv_path, header=None)  # Read CSV without header\n",
    "        parameter_names = csv_data.iloc[0].tolist()    # Extract parameter names\n",
    "        parameter_values = csv_data.iloc[1].tolist()   # Extract parameter values\n",
    "        # Create a dictionary to store parameter names and values\n",
    "        parameter_dict = {name: value for name, value in zip(parameter_names, parameter_values)}\n",
    "        # Update the Excel DataFrame with the parameter values\n",
    "        for param_name, param_value in parameter_dict.items():\n",
    "            excel_df.at[index, param_name] = param_value\n",
    "\n",
    "# Save the modified Excel DataFrame back to the same file using openpyxl (default engine for .xlsx)\n",
    "excel_df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in excel_df.iterrows():\n",
    "    subject_id = row['SubjectID']\n",
    "    spectra_csv_filename = f\"{subject_id}_power_spectra_empirical.csv\"\n",
    "    spectra_csv_path = os.path.join(csv_folder, spectra_csv_filename)\n",
    "    if os.path.exists(spectra_csv_path):\n",
    "        spectra_csv_data = pd.read_csv(spectra_csv_path, header=None)\n",
    "        channel_names = spectra_csv_data.iloc[0].tolist()\n",
    "        for col, channel_name in enumerate(channel_names):\n",
    "            for row in range(1, 5):  # Rows for delta, theta, alpha, beta\n",
    "                value = spectra_csv_data.iloc[row, col]\n",
    "                column_name = f\"{channel_name}_{spectra_csv_data.iloc[row].name}_{col + 1}\"\n",
    "                excel_df.at[index, column_name] = value\n",
    "\n",
    "excel_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in excel_df.iterrows():\n",
    "    subject_id = row['SubjectID']\n",
    "    spectra_csv_filename = f\"{subject_id}_power_spectra_simulation.csv\"\n",
    "    spectra_csv_path = os.path.join(csv_folder, spectra_csv_filename)\n",
    "    if os.path.exists(spectra_csv_path):\n",
    "        spectra_csv_data = pd.read_csv(spectra_csv_path, header=None)\n",
    "        channel_names = spectra_csv_data.iloc[0].tolist()\n",
    "        for col, channel_name in enumerate(channel_names):\n",
    "            for row in range(1, 5):  # Rows for delta, theta, alpha, beta\n",
    "                value = spectra_csv_data.iloc[row, col]\n",
    "                column_name = f\"{channel_name}_{spectra_csv_data.iloc[row].name}_{col + 1}\"\n",
    "                excel_df.at[index, column_name] = value\n",
    "\n",
    "excel_df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "# Filter out rows with missing parameter values\n",
    "filtered_data = data.dropna(subset=parameter_columns, how='all')\n",
    "\n",
    "# Extract parameter values as a DataFrame\n",
    "parameter_values = filtered_data[parameter_columns]\n",
    "\n",
    "# Perform the Shapiro-Wilk test for normality\n",
    "normality_results = {}\n",
    "for parameter in parameter_columns:\n",
    "    statistic, p_value = stats.shapiro(parameter_values[parameter])\n",
    "    normality_results[parameter] = {'statistic': statistic, 'p_value': p_value}\n",
    "\n",
    "# Display the normality test results\n",
    "for parameter, result in normality_results.items():\n",
    "    print(f\"Parameter: {parameter}\")\n",
    "    print(f\"Shapiro-Wilk Statistic: {result['statistic']}\")\n",
    "    print(f\"P-Value: {result['p_value']}\")\n",
    "    if result['p_value'] > 0.05/len(parameter_columns):\n",
    "        print(\"Data appears to be normally distributed.\\n\")\n",
    "    else:\n",
    "        print(\"Data does not appear to be normally distributed.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "data_cleaned = data.dropna(subset=parameter_columns)\n",
    "\n",
    "# Split data based on class\n",
    "normal_data = data_cleaned[data_cleaned['class'] == 'normal']\n",
    "abnormal_data = data_cleaned[data_cleaned['class'] == 'abnormal']\n",
    "\n",
    "mean_similarity_normal = normal_data['Similarity'].mean()\n",
    "mean_similarity_abnormal = abnormal_data['Similarity'].mean()\n",
    "\n",
    "# Print the mean similarity values\n",
    "print(f\"Mean Similarity for Normal Subjects: {mean_similarity_normal:.2f}\")\n",
    "print(f\"Mean Similarity for Abnormal Subjects: {mean_similarity_abnormal:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Define parameter columns\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "# Drop rows with missing parameter values\n",
    "data_cleaned = data.dropna(subset=parameter_columns)\n",
    "\n",
    "# Split data based on class\n",
    "normal_data = data_cleaned[data_cleaned['class'] == 'normal']\n",
    "abnormal_data = data_cleaned[data_cleaned['class'] == 'abnormal']\n",
    "\n",
    "# Calculate the number of tests\n",
    "num_tests = len(parameter_columns)\n",
    "\n",
    "# Define the adjusted significance level using Bonferroni correction\n",
    "adjusted_alpha = 0.05 / num_tests\n",
    "\n",
    "ks_results = []\n",
    "\n",
    "for parameter in parameter_columns:\n",
    "    ks_statistic, ks_p_value = ks_2samp(normal_data[parameter], abnormal_data[parameter])\n",
    "    print(np.mean(normal_data[parameter]))\n",
    "    print(np.mean(abnormal_data[parameter]))\n",
    "    ks_results.append((parameter, ks_statistic, ks_p_value))\n",
    "\n",
    "# Create a DataFrame for K-S test results\n",
    "ks_results_df = pd.DataFrame(ks_results, columns=['Parameter', 'KS Statistic', 'p-value'])\n",
    "\n",
    "# Filter significant results after Bonferroni correction\n",
    "significant_results = ks_results_df[ks_results_df['p-value'] < adjusted_alpha]\n",
    "\n",
    "# Print significant results\n",
    "print(\"Results after Bonferroni Correction:\")\n",
    "print(significant_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=ks_results_df, x='Parameter', y='p-value', color='slategrey')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=15)\n",
    "plt.axhline(y=adjusted_alpha, color='r', linestyle='--', label='Significance Level')\n",
    "plt.xlabel('Parameter', fontsize=15)\n",
    "plt.ylabel('p-value',labelpad=15 , fontsize=15)\n",
    "plt.title('K-S Test between normal and abnormal parameter configuation', fontsize=15, pad=20)\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"K-S Test\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in significant_results.iterrows():\n",
    "    parameter = row['Parameter']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='class', y=parameter, data=data, palette={'normal': 'skyblue', 'abnormal': 'tomato'})\n",
    "    sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "    plt.title(f'{parameter}', fontsize=20, pad=20)\n",
    "    #plt.xlabel('Class', fontsize=15)\n",
    "    #plt.ylabel(parameter+\" value\", fontsize=15, labelpad=15)\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel(None)\n",
    "    #plt.xticks(fontsize=15)\n",
    "    plt.xticks([])\n",
    "    plt.yticks(fontsize=15)\n",
    "    #plt.text(0.5, 0.02, f'p-value: {row[\"p-value\"]:.3f}', fontsize=12, ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    output_dir = os.path.abspath(\"path to output\")\n",
    "    output_name = \"KS_Test_\"+parameter\n",
    "    #plt.savefig(os.path.join(output_dir, output_name+\".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Select parameter columns\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "filtered_data = data.dropna(subset=parameter_columns, how='all')\n",
    "\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Extract parameter values as a NumPy array\n",
    "parameter_values = filtered_data[parameter_columns].values\n",
    "\n",
    "z_normalized = stats.zscore(parameter_values, axis=0)\n",
    "\n",
    "abnormal_count = np.sum(filtered_data['class'] == 'abnormal')\n",
    "dotted_line_y = abnormal_count\n",
    "\n",
    "# Create a figure and plot the parameter values\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(z_normalized, cmap='RdYlBu_r', aspect='auto', vmin=-2.0, vmax=2.0)\n",
    "plt.colorbar(label='Z-Normalized Parameter Value')\n",
    "plt.title(\"Parameter Values per Subject\", fontsize=20)\n",
    "plt.yticks([dotted_line_y // 2, len(filtered_data) - dotted_line_y // 2], ['Abnormal', 'Normal'], fontsize=15)\n",
    "plt.xticks(np.arange(len(parameter_columns)), parameter_columns, rotation=45, fontsize=15)\n",
    "plt.axhline(y=dotted_line_y, color='black', linestyle='dotted')\n",
    "plt.grid(False) \n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"KS-Test Heatmap\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name+\".png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity score stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Filter and sort data\n",
    "filtered_data = data.dropna(subset=['Similarity'], how='all')\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Separate Similarity values for normal and abnormal classes\n",
    "similarity_normal = filtered_data[filtered_data['class'] == 'normal']['Similarity']\n",
    "similarity_abnormal = filtered_data[filtered_data['class'] == 'abnormal']['Similarity']\n",
    "\n",
    "# Perform KS test\n",
    "ks_statistic, p_value = stats.ks_2samp(similarity_normal, similarity_abnormal)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot histograms for normal and abnormal classes\n",
    "plt.hist(similarity_normal, bins=20, alpha=0.5, label='Normal', color='skyblue')\n",
    "plt.hist(similarity_abnormal, bins=20, alpha=0.5, label='Abnormal', color='tomato')\n",
    "\n",
    "plt.xlabel('Dissimilarity', labelpad=20, fontsize=15)\n",
    "plt.ylabel('Frequency', labelpad=20, fontsize=15)\n",
    "plt.title('Distribution of Dissimilarity Values by Class', pad=20, fontsize=20)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"KS-Test Similarities\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name + \".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'KS test p-value: {p_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a box plot\n",
    "boxplot = plt.boxplot([similarity_normal, similarity_abnormal], labels=['Normal', 'Abnormal'], patch_artist=True)\n",
    "# Set the colors for normal and abnormal boxes\n",
    "colors = ['skyblue', 'tomato']\n",
    "for box, color in zip(boxplot['boxes'], colors):\n",
    "    box.set(facecolor=color)\n",
    "plt.ylabel('Dissimilarity Score', labelpad=15, fontsize=15)\n",
    "plt.title('Dissimilarity between groups', pad=20, fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.grid(True)\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"KS-Test Similarities Box Plot\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Filter and sort data\n",
    "filtered_data = data.dropna(subset=['Similarity', 'Initial Similarity'], how='all')\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Calculate the mean \"Initial Similarity\" and mean \"Similarity\" for normal and abnormal classes\n",
    "mean_initial_similarity_normal = filtered_data[filtered_data['class'] == 'normal']['Initial Similarity'].mean()\n",
    "mean_similarity_normal = filtered_data[filtered_data['class'] == 'normal']['Similarity'].mean()\n",
    "\n",
    "mean_initial_similarity_abnormal = filtered_data[filtered_data['class'] == 'abnormal']['Initial Similarity'].mean()\n",
    "mean_similarity_abnormal = filtered_data[filtered_data['class'] == 'abnormal']['Similarity'].mean()\n",
    "\n",
    "# Create a bar plot\n",
    "categories = ['Normal', 'Abnormal']\n",
    "x = np.arange(len(categories))\n",
    "width = 0.3  # Adjust this value for slimmer or wider bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))  # Adjust the figure size here\n",
    "bar1 = ax.bar(x - width/2, [mean_initial_similarity_normal, mean_initial_similarity_abnormal], width, label='Initial Dissimilarity', color='orange')\n",
    "bar2 = ax.bar(x + width/2, [mean_similarity_normal, mean_similarity_abnormal], width, label='Dissimilarity after fitting', color='limegreen')\n",
    "\n",
    "ax.set_xlabel('Class', labelpad=20, fontsize=15)\n",
    "ax.set_ylabel('Mean Dissimilarity Score', labelpad=20, fontsize=15)\n",
    "ax.set_title('Initial Dissimilarity vs Dissimilarity after fitting', pad=20, fontsize=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, fontsize=15)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"Difference_Plot\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Filter and sort data\n",
    "filtered_data = data.dropna(subset=['Similarity', 'Initial Similarity'], how='all')\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Calculate the mean \"Initial Similarity\" and mean \"Similarity\" for normal and abnormal classes\n",
    "mean_initial_similarity_normal = filtered_data[filtered_data['class'] == 'normal']['Initial Similarity'].mean()\n",
    "mean_similarity_normal = filtered_data[filtered_data['class'] == 'normal']['Similarity'].mean()\n",
    "mean_initial_similarity_abnormal = filtered_data[filtered_data['class'] == 'abnormal']['Initial Similarity'].mean()\n",
    "mean_similarity_abnormal = filtered_data[filtered_data['class'] == 'abnormal']['Similarity'].mean()\n",
    "\n",
    "# Convert mean values to reversed percentages\n",
    "reversed_percentage_initial_similarity_normal = 100 - (mean_initial_similarity_normal * 100)\n",
    "reversed_percentage_similarity_normal = 100 -(mean_similarity_normal * 100)\n",
    "reversed_percentage_initial_similarity_abnormal = 100 - (mean_initial_similarity_abnormal * 100)\n",
    "reversed_percentage_similarity_abnormal = 100 - (mean_similarity_abnormal * 100)\n",
    "\n",
    "# Create a bar plot\n",
    "categories = ['Normal', 'Abnormal']\n",
    "x = np.arange(len(categories))\n",
    "width = 0.3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "bar1 = ax.bar(x - width/2, [reversed_percentage_initial_similarity_normal, reversed_percentage_initial_similarity_abnormal], width, label='Initial Similarity', color='tomato')\n",
    "bar2 = ax.bar(x + width/2, [reversed_percentage_similarity_normal, reversed_percentage_similarity_abnormal], width, label='Similarity after fitting', color='limegreen')\n",
    "\n",
    "ax.set_xlabel('Class', labelpad=20, fontsize=15)\n",
    "ax.set_ylabel('Similarity [%]', labelpad=20, fontsize=15)\n",
    "ax.set_title('Initial Similarity vs Similarity after fitting', pad=20, fontsize=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories, fontsize=15)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.subplots_adjust(right=0.7)\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"Similarity_difference_for_presentation\"\n",
    "plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Filter and sort data\n",
    "filtered_data = data.dropna(subset=['Similarity', 'age'], how='any')\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Separate Similarity values and ages for normal subjects\n",
    "similarity_normal = filtered_data[filtered_data['class'] == 'normal']\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot scatter plot of similarity values by age for normal subjects\n",
    "plt.scatter(similarity_normal['age'], similarity_normal['Similarity'], color='skyblue', alpha=0.5)\n",
    "plt.xlabel('Age', labelpad=20, fontsize=15)\n",
    "plt.ylabel('Dissimilarity', labelpad=20, fontsize=15)\n",
    "plt.title('Distribution of Similarity Values by Age (Normal Subjects)', pad=20, fontsize=20)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"KS-Test Similarities by Age in Normal Subjects\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "data = pd.read_excel('path to file')\n",
    "\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "filtered_data = data.dropna(subset=['age'] + parameter_columns, how='any')\n",
    "normal_data = filtered_data[filtered_data['class'] == 'normal']\n",
    "\n",
    "# Calculate the number of tests\n",
    "num_tests = len(parameter_columns)\n",
    "\n",
    "correlation_results = {}\n",
    "alpha = 0.05 / num_tests  # Bonferroni-corrected alpha\n",
    "for param in parameter_columns:\n",
    "    pearson_corr, pearson_p_value = pearsonr(normal_data['age'], normal_data[param])\n",
    "    \n",
    "    # Apply Bonferroni correction to the p-value\n",
    "    bonferroni_corrected_pearson_p_value = min(pearson_p_value * num_tests, 1)\n",
    "    \n",
    "    correlation_results[param] = {\n",
    "        'Pearson Correlation': pearson_corr,\n",
    "        'Pearson p-value': bonferroni_corrected_pearson_p_value,\n",
    "    }\n",
    "    \n",
    "for param, results in correlation_results.items():\n",
    "    print(f\"Parameter: {param}\")\n",
    "    print(f\"Pearson Correlation: {results['Pearson Correlation']:.3f}, p-value: {results['Pearson p-value']:.4f}\")\n",
    "    if results['Pearson p-value'] < alpha:\n",
    "        print(\"There is a significant correlation with age.\")\n",
    "    else:\n",
    "        print(\"There is no significant correlation with age.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "significant_parameters = []\n",
    "trend_lines = {}\n",
    "\n",
    "for param, results in correlation_results.items():\n",
    "    if results['Pearson p-value'] < alpha:\n",
    "        significant_parameters.append(param)\n",
    "        \n",
    "for param in significant_parameters:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(normal_data['age'], normal_data[param], alpha=0.5, label=\"Data\")\n",
    "\n",
    "    # Calculate the trend line using numpy's polyfit function\n",
    "    slope, intercept = np.polyfit(normal_data['age'], normal_data[param], 1)\n",
    "    trend_lines[param] = (slope, intercept)\n",
    "\n",
    "    # Plot the trend line\n",
    "    plt.plot(normal_data['age'], slope * normal_data['age'] + intercept, color='red', label=\"Trend Line\")\n",
    "\n",
    "    plt.title(f\"Correlation between age and {param}\", fontsize=20)\n",
    "    plt.xlabel(\"Age\", fontsize=15)\n",
    "    plt.ylabel(param, fontsize=15)\n",
    "    plt.grid(True)\n",
    "    output_dir = os.path.abspath(\"path to output\")\n",
    "    output_name = \"Correlation between age and tau\"\n",
    "    plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_coeffs = np.array([results['Pearson Correlation'] for results in correlation_results.values()])\n",
    "p_values = np.array([results['Pearson p-value'] for results in correlation_results.values()])\n",
    "param_names = list(correlation_results.keys())\n",
    "\n",
    "# Set significance threshold (e.g., p-value < 0.05)\n",
    "significance_threshold = alpha\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "#plt.bar(param_names, correlation_coeffs, color='skyblue', label='Correlation Coefficient')\n",
    "plt.bar(param_names, p_values, color='sandybrown', alpha=0.7)\n",
    "plt.axhline(y=significance_threshold, color='red', linestyle='dashed', label='Significance Threshold')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylabel('p-value', fontsize=20)\n",
    "plt.title('Correlation with Age for Parameter Values', fontsize=20)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"Correlation Age in Normal Subjects\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "data_cleaned = data.dropna(subset=parameter_columns)\n",
    "\n",
    "# Split data based on class\n",
    "normal_data = data_cleaned[data_cleaned['class'] == 'normal']\n",
    "abnormal_data = data_cleaned[data_cleaned['class'] == 'abnormal']\n",
    "\n",
    "t_test_results = []\n",
    "\n",
    "for parameter in parameter_columns:  # Replace with your actual parameter column names\n",
    "    t_test_statistic, t_test_p_value = ttest_ind(normal_data[parameter], abnormal_data[parameter])\n",
    "    t_test_results.append((parameter, t_test_statistic, t_test_p_value))\n",
    "\n",
    "# Create a DataFrame for K-S test results\n",
    "t_test_results_df = pd.DataFrame(t_test_results, columns=['Parameter', 'T-test Statistic', 'p-value'])\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Filter significant results\n",
    "t_test_results = t_test_results_df[t_test_results_df['p-value'] < alpha]\n",
    "\n",
    "# Print significant results\n",
    "print(\"Results:\")\n",
    "print(t_test_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=t_test_results_df, x='Parameter', y='p-value', palette='coolwarm')\n",
    "plt.xticks(rotation=45, ha='right', fontsize=15)\n",
    "plt.axhline(y=alpha, color='r', linestyle='--', label='Significance Level')\n",
    "plt.xlabel('Parameter', fontsize=15)\n",
    "plt.ylabel('p-value',labelpad=15 , fontsize=15)\n",
    "plt.title('T-Test between normal and abnormal parameter configuation', fontsize=15)\n",
    "plt.legend(fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"T-Test\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name+\".png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in t_test_results.iterrows():\n",
    "    parameter = row['Parameter']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='class', y=parameter, data=data, palette='coolwarm')\n",
    "    plt.title(f'Box Plot for {parameter}', fontsize=20)\n",
    "    plt.xlabel('Class', fontsize=15)\n",
    "    plt.ylabel(parameter+\" value\", fontsize=15, labelpad=15)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.text(0.5, 0.02, f'p-value: {row[\"p-value\"]:.3f}', fontsize=12, ha='center', va='center', transform=plt.gca().transAxes)\n",
    "    plt.gcf().set_facecolor('white')\n",
    "    output_dir = os.path.abspath(\"path to output\")\n",
    "    output_name = \"T-Test \"+parameter\n",
    "    #plt.savefig(os.path.join(output_dir, output_name+\".png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('path to file')\n",
    "\n",
    "# Select parameter columns\n",
    "parameter_columns = ['tau', 'I', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'alpha', 'beta', 'gamma']\n",
    "\n",
    "filtered_data = data.dropna(subset=parameter_columns, how='all')\n",
    "\n",
    "filtered_data = filtered_data.sort_values(by=['class'])\n",
    "\n",
    "# Extract parameter values as a NumPy array\n",
    "parameter_values = filtered_data[parameter_columns].values\n",
    "\n",
    "z_normalized = stats.zscore(parameter_values, axis=0)\n",
    "\n",
    "# Create a figure and plot the parameter values\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(z_normalized, cmap='RdYlBu_r', aspect='auto', vmin=-3.0, vmax=3.0)\n",
    "plt.colorbar(label='Parameter Value')\n",
    "plt.title(\"Parameter Values per Subject\")\n",
    "plt.xticks(np.arange(len(parameter_columns)), parameter_columns, rotation=45)\n",
    "plt.ylabel(\"Subjects\")\n",
    "plt.grid(False) \n",
    "output_dir = os.path.abspath(\"path to output\")\n",
    "output_name = \"T-Test Heatmap\"\n",
    "#plt.savefig(os.path.join(output_dir, output_name+\".png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract initial similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file initial_params_myscript_digital_twins.py\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# import libraries\n",
    "\n",
    "from statistics import mean\n",
    "import mne\n",
    "from tvb.simulator.lab import *\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.integrate import simps\n",
    "import pandas as pd\n",
    "from scipy.optimize import dual_annealing\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "jobid=int(os.environ[\"PBS_ARRAY_INDEX\"])\n",
    "print('job id')\n",
    "print(jobid)\n",
    "\n",
    "# Run the necessary code here...\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# the eeg simulation function that will use TVB\n",
    "\n",
    "def simulateeeg(params):\n",
    "    #start = timer();\n",
    "    \n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # Set up the model including assigning parameters  \n",
    "    \n",
    "    model = models.Generic2dOscillator(\n",
    "        tau = np.array([params[0]]), \n",
    "        I = np.array([params[1]]),\n",
    "        a = np.array([params[2]]),\n",
    "        b = np.array([params[3]]),\n",
    "        c = np.array([params[4]]),\n",
    "        d = np.array([params[5]]),\n",
    "        e = np.array([params[6]]),\n",
    "        f = np.array([params[7]]),\n",
    "        g = np.array([params[8]]),\n",
    "        alpha = np.array([params[9]]),\n",
    "        beta = np.array([params[10]]),\n",
    "        gamma = np.array([params[11]]))                     \n",
    "    \n",
    "    con = connectivity.Connectivity.()\n",
    "    coupl = coupling.Linear(a=np.array([1]))\n",
    "    nsigma = np.array([0.01,])\n",
    "    hiss = noise.Additive(nsig = nsigma)\n",
    "    heunint = integrators.HeunStochastic(dt=0.1, noise=hiss)\n",
    "    rm = region_mapping.RegionMapping.from_file()\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # Attach an EEG forward model (a \"monitor\")\n",
    "    \n",
    "    mon_EEG = monitors.EEG.()\n",
    "    mon_EEG.region_mapping=rm\n",
    "    mon_EEG.period=(1/250)*1000 \n",
    "    mon_EEG.reference=\"average\"\n",
    "    mons = (mon_EEG,)\n",
    "\n",
    "    # - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "    # Run the model \n",
    "    \n",
    "    sim = simulator.Simulator(model=model, connectivity=con,\n",
    "                          coupling=coupl,\n",
    "                          integrator=heunint, monitors=mons)\n",
    "    sim.configure()\n",
    "    \n",
    "    eeg = sim.run(simulation_length=5000)\n",
    "    \n",
    "    return eeg[0][1]\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# Normalization \n",
    "\n",
    "def eegnormalization(eeg):\n",
    "    \n",
    "    eeg = stats.zscore(eeg, axis=1)\n",
    "    \n",
    "    return eeg\n",
    "    \n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# the eeg comparison function that will return\n",
    "# a 'distance' for how dissimilar the two\n",
    "# eeg time series are\n",
    "    \n",
    "def calculate_bands(eeg, fs):\n",
    "    \n",
    "    num_channels = eeg.shape[0]\n",
    "    \n",
    "    power_spectrum = np.zeros((num_channels, 4))\n",
    "    \n",
    "    for channel_idx in range(num_channels):\n",
    "\n",
    "        freqs, psd = signal.welch(eeg[channel_idx], fs=fs, nperseg=4*fs)\n",
    "        freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "        power_spectrum_channel = []\n",
    "\n",
    "        idx_beta = np.logical_and(freqs >= beta_low, freqs <= beta_high)\n",
    "        idx_alpha = np.logical_and(freqs >= alpha_low, freqs <= alpha_high)\n",
    "        idx_theta = np.logical_and(freqs >= theta_low, freqs <= theta_high)\n",
    "        idx_delta = np.logical_and(freqs >= delta_low, freqs <= delta_high)\n",
    "\n",
    "        power_spectrum_channel.append(simps(psd[idx_delta], dx=freq_res))\n",
    "        power_spectrum_channel.append(simps(psd[idx_theta], dx=freq_res))\n",
    "        power_spectrum_channel.append(simps(psd[idx_alpha], dx=freq_res))   \n",
    "        power_spectrum_channel.append(simps(psd[idx_beta], dx=freq_res))   \n",
    "        \n",
    "        power_spectrum[channel_idx] = np.array(power_spectrum_channel)\n",
    "    \n",
    "    return power_spectrum\n",
    "\n",
    "def calculate_similarity(eeg1, empirical_power, fs):\n",
    "    \n",
    "    num_channels = eeg1.shape[0]\n",
    "\n",
    "    power_spectrum = calculate_bands(eeg1, fs)  \n",
    "    \n",
    "    overall_similarity = []\n",
    "    \n",
    "    for channel_idx in range(num_channels):\n",
    "        \n",
    "        similarity_channel = spatial.distance.cosine(power_spectrum[channel_idx], empirical_power[channel_idx])\n",
    "        overall_similarity.append(similarity_channel)\n",
    "\n",
    "    similarity_score = np.mean(overall_similarity)\n",
    " \n",
    "    return similarity_score\n",
    " \n",
    "#------------------------\n",
    "# Set up parameters\n",
    "\n",
    "beta_low, beta_high = 12, 30\n",
    "alpha_low, alpha_high = 8, 12\n",
    "theta_low, theta_high = 4, 8\n",
    "delta_low, delta_high = 1, 4\n",
    "\n",
    "fs = 250\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# define the starting point in the parameter space\n",
    "# (obviously the size of this will depend on what\n",
    "# parameters are actually IN your TVB model)\n",
    "\n",
    "params0 = [1.0, 0.0, -2.0, -10.0, 0.0, 0.02, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# import the targeteeg data\n",
    "\n",
    "file_path = 'path to fil\e'\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "subjects = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    key = row['setfile']\n",
    "    id_value = row['id']\n",
    "    class_value = row['class']\n",
    "    subjects[key] = {'id': id_value, 'class': class_value}\n",
    "\n",
    "subject_name = list(subjects.keys())[jobid-1]\n",
    "\n",
    "print('the input file I will fit to is')\n",
    "print(subjects[subject_name]['id'])\n",
    "\n",
    "print('Loading a raw EEG file...')\n",
    "\n",
    "data = mne.io.read_epochs_eeglab(subject_name)\n",
    "\n",
    "channels = data.ch_names\n",
    "\n",
    "raw_data = (data.get_data().squeeze())\n",
    "\n",
    "raw_data = raw_data[:60, :, :1250]\n",
    "\n",
    "targeteeg_power = []\n",
    "\n",
    "for i in range(raw_data.shape[0]):\n",
    "\n",
    "    targeteeg_epoch = eegnormalization(raw_data[i])\n",
    "\n",
    "    epoch_spectrum = calculate_bands(targeteeg_epoch, fs)\n",
    "    \n",
    "    targeteeg_power.append(epoch_spectrum)\n",
    "    \n",
    "targeteeg_spectrum = np.mean(np.array(targeteeg_power), axis=0) \n",
    "\n",
    "    \n",
    "initial_simulation = simulateeeg(params0)\n",
    "initialEEG = np.squeeze(initial_simulation).T\n",
    "initialEEG = initialEEG[:raw_data.shape[1],:1250]\n",
    "initialEEG = eegnormalization(initialEEG)\n",
    "\n",
    "initialEEG_similarity = calculate_similarity(initialEEG, targeteeg_spectrum, fs)\n",
    "\n",
    "file_name = os.path.basename(subject_name)\n",
    "output_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "output_file_dir = 'path to output\'\n",
    "\n",
    "# File \n",
    "initial_similarity_filename = os.path.join(output_file_dir, f\"{output_name}_initial_similarity.csv\")\n",
    "with open(initial_similarity_filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([initialEEG_similarity])\n",
    "\n",
    "\n",
    "print('my output will be')\n",
    "print(initial_similarity_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project_scott]",
   "language": "python",
   "name": "conda-env-project_scott-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
